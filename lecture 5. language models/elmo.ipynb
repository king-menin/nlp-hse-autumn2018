{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "elmo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "XbrcWnYoiA0P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Языковые модели для классификации"
      ]
    },
    {
      "metadata": {
        "id": "dGP4FeQ3b3m5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import keras.layers as layers\n",
        "\n",
        "from collections import Counter\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.layers import Input, Embedding, BatchNormalization, LSTM, Dense, Concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.utils import plot_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iA4tUfNab3nC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Загружаем IMDB dataset"
      ]
    },
    {
      "metadata": {
        "id": "6bZvbbkTb3nD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Load all files from a directory in a DataFrame.\n",
        "def load_directory_data(directory):\n",
        "    data = {}\n",
        "    data[\"sentence\"] = []\n",
        "    data[\"sentiment\"] = []\n",
        "  \n",
        "    for file_path in os.listdir(directory):\n",
        "        with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "          data[\"sentence\"].append(f.read())\n",
        "          data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "     \n",
        "    return pd.DataFrame.from_dict(data)\n",
        "\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "    pos_df[\"polarity\"] = 1\n",
        "    neg_df[\"polarity\"] = 0\n",
        "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "    dataset = tf.keras.utils.get_file(\n",
        "        fname=\"aclImdb.tar.gz\", \n",
        "        origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "        extract=True)\n",
        " \n",
        "    train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "    test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "# Load and process the dataset files from local storage.\n",
        "def download_and_load_datasets_local(force_download=False):\n",
        "  \n",
        "    train_df = load_dataset(os.path.join(os.path.dirname(\"./dataset/\"), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "    test_df = load_dataset(os.path.join(os.path.dirname(\"./dataset/\"), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "    train_df.append(test_df, ignore_index=True)\n",
        "    \n",
        "    train_df, test_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
        "  \n",
        "    return train_df, test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7hv-GZw1cxEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "aa79da4d-d8c6-414a-b594-8bbed188bddb"
      },
      "cell_type": "code",
      "source": [
        "train_df, test_df = download_and_load_datasets()\n",
        "print(train_df.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 8s 0us/step\n",
            "                                            sentence sentiment  polarity\n",
            "0  The Bible teaches us that the love of money is...        10         1\n",
            "1  *I mark where there are spoilers! Overall comm...        10         1\n",
            "2  ...let me count the ways.<br /><br />1. A titl...         1         0\n",
            "3  Despite being quite far removed from my expect...         8         1\n",
            "4  This is a very entertaining flick, considering...         9         1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QzkhQTy3b3nI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Построим словарь"
      ]
    },
    {
      "metadata": {
        "id": "opmd_a8-b3nJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# parameter of max word length\n",
        "time_steps = 100\n",
        "\n",
        "\n",
        "# building vocabulary from dataset\n",
        "def build_vocabulary(sentence_list):\n",
        "    unique_words = \" \".join(sentence_list).strip().split()\n",
        "    word_count = Counter(unique_words).most_common()\n",
        "    vocabulary = {}\n",
        "    for word, _ in word_count:\n",
        "        vocabulary[word] = len(vocabulary)        \n",
        "\n",
        "    return vocabulary\n",
        "\n",
        "\n",
        "# Get vocabulary vectors from document list\n",
        "# Vocabulary vector, Unknown word is 1 and padding is 0\n",
        "# INPUT: raw sentence list\n",
        "# OUTPUT: vocabulary vectors list\n",
        "def get_voc_vec(document_list, vocabulary):    \n",
        "    voc_ind_sentence_list = []\n",
        "    for document in document_list:\n",
        "        voc_idx_sentence = []\n",
        "        word_list = document.split()\n",
        "        \n",
        "        for w in range(time_steps):\n",
        "            if w < len(word_list):\n",
        "                # pickup vocabulary id and convert unknown word into 1\n",
        "                voc_idx_sentence.append(vocabulary.get(word_list[w], -1) + 2)\n",
        "            else:\n",
        "                # padding with 0\n",
        "                voc_idx_sentence.append(0)\n",
        "            \n",
        "        voc_ind_sentence_list.append(voc_idx_sentence)\n",
        "        \n",
        "    return np.array(voc_ind_sentence_list)\n",
        "\n",
        "\n",
        "vocabulary = build_vocabulary(train_df[\"sentence\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pC_Je1IBb3nN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Создаем ELMo модель для классификации\n",
        "Загружаем модель с tensorflow hub"
      ]
    },
    {
      "metadata": {
        "id": "JTXLGcHCb3nO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reduce TensorFlow logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# Instantiate the elmo model\n",
        "elmo_module = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
        "\n",
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "\n",
        "K.set_learning_phase(1)\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtryHLjxb3nR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Создаем генератор батчей"
      ]
    },
    {
      "metadata": {
        "id": "Lx6ggn80b3nT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# mini-batch generator\n",
        "def batch_iter(data, labels, batch_size, shuffle=True):\n",
        "    num_batches_per_epoch = int((len(data) - 1) / batch_size) + 1\n",
        "    print(\"batch_size\", batch_size)\n",
        "    print(\"num_batches_per_epoch\", num_batches_per_epoch)\n",
        "\n",
        "    def data_generator():\n",
        "        data_size = len(data)\n",
        "\n",
        "        while True:\n",
        "            # Shuffle the data at each epoch\n",
        "            if shuffle:\n",
        "                shuffle_indices = np.random.permutation(np.arange(data_size))\n",
        "                shuffled_data = data[shuffle_indices]\n",
        "                shuffled_labels = labels[shuffle_indices]\n",
        "            else:\n",
        "                shuffled_data = data\n",
        "                shuffled_labels = labels\n",
        "\n",
        "            for batch_num in range(num_batches_per_epoch):\n",
        "                start_index = batch_num * batch_size\n",
        "                end_index = min((batch_num + 1) * batch_size, data_size)\n",
        "                                \n",
        "                X_voc = get_voc_vec(shuffled_data[start_index: end_index], vocabulary)\n",
        "                                \n",
        "                sentence_split_list = []\n",
        "                sentence_split_length_list = []\n",
        "            \n",
        "                for sentence in shuffled_data[start_index: end_index]:    \n",
        "                    sentence_split = sentence.split()\n",
        "                    sentence_split_length = len(sentence_split)\n",
        "                    sentence_split += [\"NaN\"] * (time_steps - sentence_split_length)\n",
        "                    \n",
        "                    sentence_split_list.append((\" \").join(sentence_split))\n",
        "                    sentence_split_length_list.append(sentence_split_length)\n",
        "        \n",
        "                X_elmo = np.array(sentence_split_list)\n",
        "\n",
        "                X = [X_voc, X_elmo]\n",
        "                y = shuffled_labels[start_index: end_index]\n",
        "                \n",
        "                yield X, y\n",
        "\n",
        "    return num_batches_per_epoch, data_generator()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sClkVgKVimQi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Задаем архитектуру модели"
      ]
    },
    {
      "metadata": {
        "id": "mvnJnj_6b3nW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# embed elmo method\n",
        "def make_elmo_embedding(x):\n",
        "    embeddings = elmo_module(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"elmo\"]\n",
        "    \n",
        "    return embeddings\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "yAHt4yIub3nZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "eba5a1be-5563-4f16-f78d-e78bc76a638f"
      },
      "cell_type": "code",
      "source": [
        "# elmo embedding dimension\n",
        "elmo_dim = 1024\n",
        "\n",
        "# Input Layers\n",
        "word_input = Input(shape=(None, ), dtype='int32')  # (batch_size, sent_length)\n",
        "elmo_input = Input(shape=(None, ), dtype=tf.string)  # (batch_size, sent_length, elmo_size)\n",
        "\n",
        "# Hidden Layers\n",
        "word_embedding = Embedding(input_dim=len(vocabulary), output_dim=128, mask_zero=True)(word_input)\n",
        "elmo_embedding = layers.Lambda(make_elmo_embedding, output_shape=(None, elmo_dim))(elmo_input)\n",
        "word_embedding = Concatenate()([word_embedding, elmo_embedding])\n",
        "word_embedding = BatchNormalization()(word_embedding)\n",
        "x = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(word_embedding)\n",
        "\n",
        "# Output Layer\n",
        "predict = Dense(units=1, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=[word_input, elmo_input], outputs=predict)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 128)    35918976    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, None, 1024)   0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, 1152)   0           embedding_1[0][0]                \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, 1152)   4608        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 128)          655872      batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            129         lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 36,579,585\n",
            "Trainable params: 36,577,281\n",
            "Non-trainable params: 2,304\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n5lkmdNiit5M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Создадим данные"
      ]
    },
    {
      "metadata": {
        "id": "uhZGq5tgb3ne",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_text = train_df['sentence'].tolist()\n",
        "train_text = [' '.join(t.split()[0:time_steps]) for t in train_text]\n",
        "train_text = np.array(train_text)\n",
        "train_label = np.array(train_df['polarity'].tolist())\n",
        "\n",
        "test_text = test_df['sentence'].tolist()\n",
        "test_text = [' '.join(t.split()[0:time_steps]) for t in test_text]\n",
        "test_text = np.array(test_text)\n",
        "test_label = np.array(test_df['polarity'].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n5WOt9vFb3ni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7f6b591f-7db4-4f22-ace8-bd313866894b"
      },
      "cell_type": "code",
      "source": [
        "# mini-batch size\n",
        "batch_size = 32\n",
        "\n",
        "train_steps, train_batches = batch_iter(train_text,\n",
        "                                        np.array(train_df[\"polarity\"]),\n",
        "                                        batch_size)\n",
        "valid_steps, valid_batches = batch_iter(test_text,\n",
        "                                        np.array(test_df[\"polarity\"]),\n",
        "                                        batch_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_size 32\n",
            "num_batches_per_epoch 782\n",
            "batch_size 32\n",
            "num_batches_per_epoch 782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2ZV4pn2fb3nm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9560d59f-dd36-4325-f498-f17a993bf69a"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(train_batches, train_steps,\n",
        "                              epochs=5,\n",
        "                              validation_data=valid_batches,\n",
        "                              validation_steps=valid_steps,\n",
        "                              callbacks=[tb_cb])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "715/782 [==========================>...] - ETA: 2:31 - loss: 0.5188 - acc: 0.7451"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I058u45Vb3nw",
        "colab_type": "code",
        "colab": {},
        "outputId": "f2b904d2-548a-4142-bb79-79ce2b1ca9fc"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate_generator(valid_batches, valid_steps)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy;', score[1])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 1.0284352650165558\n",
            "Test accuracy; 0.77596\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}